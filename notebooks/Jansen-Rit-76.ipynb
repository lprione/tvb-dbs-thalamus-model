{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb2e2df2",
   "metadata": {},
   "source": [
    "# Import libraries for SBI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280fb313",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib.externals.loky import set_loky_pickler\n",
    "set_loky_pickler(\"dill\")\n",
    "\n",
    "from sbi.analysis import pairplot\n",
    "from sbi.inference import SNPE, simulate_for_sbi, prepare_for_sbi #deprecated, removed in next release\n",
    "from sbi.utils import BoxUniform\n",
    "from sbi.utils.user_input_checks import (\n",
    "    check_sbi_inputs,\n",
    "    process_prior,\n",
    "    process_simulator,\n",
    ")\n",
    "from sbi import utils as utils\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.integrate import odeint\n",
    "from scipy.stats import gaussian_kde"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e99662b6",
   "metadata": {},
   "source": [
    "# Import libraries for TVB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cbe07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "\n",
    "from tvb.simulator.lab import *\n",
    "from tvb.simulator.plot.tools import *\n",
    "from tvb.datatypes.time_series import TimeSeriesRegion\n",
    "from simulation_wrapper import simulation_wrapper_func\n",
    "\n",
    "from scipy import io\n",
    "from scipy import signal\n",
    "from scipy.io import savemat\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import time as tm\n",
    "import h5py\n",
    "import sys\n",
    "import os\n",
    "#import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b22b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_min = [2.6,17.6, 0.05, 0.025] #17.6\n",
    "prior_max = [9.75,110.0, 0.15, 0.075]\n",
    "prior_jr = BoxUniform(low=torch.as_tensor(prior_min), high=torch.as_tensor(prior_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c769f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_wrapper_prepared, prior_jr_prepared = prepare_for_sbi(simulation_wrapper_func, prior_jr);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba4b5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start clock for saving running time:\n",
    "start_time = tm.time()\n",
    "\n",
    "# Next, we need simulations, or more specifically, pairs of parameters theta\n",
    "# which we sample from the prior and corresponding simulations x = simulator(theta).\n",
    "# The sbi helper function called simulate_for_sbi allows to parallelize your code with joblib.\n",
    "num_sim = 1\n",
    "workers_num = 64\n",
    "sim_params_jr, sim_eeg_jr = simulate_for_sbi(simulation_wrapper_prepared, proposal=prior_jr_prepared, num_simulations=num_sim, num_workers=workers_num);\n",
    "\n",
    "end_time = tm.time()\n",
    "sim_run_time = end_time - start_time\n",
    "\n",
    "#print(\"simulation run time:\", sim_run_time)\n",
    "\n",
    "#print(\"sim_params_jr.shape\", sim_params_jr.shape)\n",
    "#print(\"sim_eeg_jr.shape\", sim_eeg_jr.shape)\n",
    "\n",
    "# detect and return # of NaN sim\n",
    "nan_mask = torch.isnan(sim_eeg_jr[:,0])\n",
    "num_nan = nan_mask.sum().item()\n",
    "print(\"Number of NaN sim:\",num_nan)\n",
    "\n",
    "# detect and return # of Inf sim\n",
    "inf_mask = torch.isinf(sim_eeg_jr[:,0])\n",
    "num_inf = inf_mask.sum().item()\n",
    "print(\"Number of Inf sim:\",num_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2daa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(sim_params_jr, 'sim_params_jr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2eb248",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sim_eeg_jr_374.npy', sim_eeg_jr)\n",
    "#torch.save(sim_eeg_jr, 'sim_eeg_jr.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3acbcda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_params_jr = torch.load('sim_params_jr.pt');\n",
    "sim_eeg_jr = torch.load('sim_eeg_jr.pt');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96baa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = np.linspace(0,30,120000)\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.plot(time[2000:8000],sim_eeg_jr[0,2000:8000,:],'k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1357dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chunks = torch.chunk(sim_eeg_jr, 10, dim=0)\n",
    "\n",
    "#for i, chunk in enumerate(chunks):\n",
    "    #chunk_numpy = chunk.numpy()\n",
    "    #np.save(f'data_chunk_{i+1}.npy', chunk_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9196f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = h5py.File('avg_final.mat', 'r')\n",
    "signal = torch.tensor(mat['avg_final'][:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75935d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = signal.permute(2,0,1)\n",
    "signal = signal[:,:,:]/600;\n",
    "signal = np.delete(signal, [52,55], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b874abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,10))\n",
    "plt.plot(np.linspace(-50, 200, 1001),signal[0,:,:],'k')\n",
    "plt.ylim(-0.02, 0.02)\n",
    "print(signal.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d9b12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = sim_eeg_jr.shape[0]  #total number of simulations, which is 10k\n",
    "initial_offset = 250 * 4  #index of the first stimulation\n",
    "samples_per_stimulation = 500 * 4  #distance between stimulations\n",
    "pre_stimulus = 50 * 4  #window of samples before the stimulation\n",
    "post_stimulus = 200 * 4  #window of samples after the stimulation\n",
    "window_size = pre_stimulus + post_stimulus  #total size of the window around each stimulation\n",
    "\n",
    "#initialize an empty list to store the average window for each simulation\n",
    "averaged_trials = []\n",
    "\n",
    "#loop through each simulation to extract, average, and store windows\n",
    "for sim in range(num_simulations):\n",
    "    windows = []  #temporary list to store windows for the current simulation\n",
    "\n",
    "    #generate indices for stimulations, starting from `initial_offset` and spaced by `samples_per_stimulation`\n",
    "    stim_indices = torch.arange(initial_offset, sim_eeg_jr.shape[1] - samples_per_stimulation, samples_per_stimulation)\n",
    "    \n",
    "    #for each stimulation point in the current simulation\n",
    "    for idx in stim_indices:\n",
    "        start_idx = idx - pre_stimulus  #start of window\n",
    "        end_idx = idx + post_stimulus  #end of window\n",
    "        \n",
    "        #extract the window of data around the current stimulation for all channels\n",
    "        #shape of `window` will be (window_size, 65)\n",
    "        window = sim_eeg_jr[sim, start_idx:end_idx, :]  \n",
    "        \n",
    "        #append the extracted window to the `windows` list\n",
    "        windows.append(window)\n",
    "\n",
    "    #stack all windows for the current simulation along a new dimension\n",
    "    #`windows` now has shape (num_trials, window_size, 65), where num_trials is the number of stimulations\n",
    "    windows = torch.stack(windows, dim=0)\n",
    "    \n",
    "    #calculate the mean across all trials for the current simulation\n",
    "    #resulting shape: (window_size, 65)\n",
    "    avg_trial = windows.mean(dim=0)\n",
    "    \n",
    "    #append the averaged window for this simulation to the list `averaged_trials`\n",
    "    averaged_trials.append(avg_trial)\n",
    "\n",
    "#stack all simulations' averaged windows along a new dimension to get the final result\n",
    "#`final_result` now has shape (10k, window_size, 65)\n",
    "final_result = torch.stack(averaged_trials, dim=0)\n",
    "\n",
    "#print the shape to verify it matches (10k, window_size, 65)\n",
    "print(final_result.shape)  #should output: (10k, 1000, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b8af1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we instantiate the inference object \n",
    "inference = SNPE(prior=prior_jr)\n",
    "print(inference)\n",
    "\n",
    "# We then pass the simulated data to the inference object.\n",
    "sim_eeg_jr_compare = signal.reshape(10_000, -1)\n",
    "sim_eeg_jr_compare = sim_eeg_jr_compare.float()\n",
    "sim_eeg_jr_compare.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5f5afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_jr = inference.append_simulations(sim_params_jr, sim_eeg_jr_compare)\n",
    "\n",
    "# Next, we train the neural density estimator to learn the association\n",
    "# between the simulated data (or data features) and the underlying parameters:\n",
    "density_estimator_forward = inference_jr.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de81f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can use the density estimator to the built the posterior distribution.\n",
    "# Meaning, the distributions over the parameters given the data.\n",
    "posterior_jr = inference_jr.build_posterior(density_estimator_forward, sample_with='mcmc')\n",
    "print(posterior_jr) # prints how the posterior was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('avg_trial.mat')\n",
    "signal = mat['avg_trial']\n",
    "sim_eeg_obs = torch.tensor(signal.T)\n",
    "sim_eeg_obs = np.delete(sim_eeg_obs, [52,55], 1)\n",
    "\n",
    "# Now, we would generate the \"experimental\" observation.\n",
    "sim_params_jr_true = torch.tensor([[ 6.3861, 66.3435,  1.3794,  0.8769]])\n",
    "#sim_eeg_obs = simulation_wrapper_prepared(sim_params_jr_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc19d4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot EEG\n",
    "teeg = np.linspace(-50,200,1001)\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.plot(teeg[:],sim_eeg_obs[:,:],'k')\n",
    "plt.ylim(-0.05, 0.05)\n",
    "plt.title(\"All EEG channels\")\n",
    "\n",
    "plt.figure(figsize=(7,10))\n",
    "plt.plot(teeg[:],sim_eeg_obs[:,0], teeg[:],sim_eeg_obs[:,1], 'k')\n",
    "plt.ylim(-0.05, 0.05)\n",
    "plt.title(\"EEG channel 1-2\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c713e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_trial_remodel = sim_eeg_obs.reshape(-1)\n",
    "avg_trial_remodel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72124c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given the observation, we can sample from the posterior our p(theta|x_obs) and visualise the marginals for the parameters.\n",
    "samples = posterior_jr.sample((1000,), x=avg_trial_remodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1a23a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairplot(samples, points=sim_params_jr_true, limits=[[2.6,9.75], [17.6,110.0], [1.5,2.5], [0.75,1.25]], figsize=(6, 6), labels=[r\"$A$\", r\"$B$\", r\"$a$\", r\"$b$\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6efe0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select max posterior for all parameters and run\n",
    "numsamples = 1000\n",
    "# post_values = posterior_jr.sample((numsamples,),x=sim_eeg_obs_compare)\n",
    "post_values_A = samples[:,0]\n",
    "post_values_B = samples[:,1]\n",
    "post_values_a = samples[:,2]\n",
    "post_values_b = samples[:,3]\n",
    "kde_sim_A = gaussian_kde(post_values_A, bw_method='scott')\n",
    "kde_sim_B = gaussian_kde(post_values_B, bw_method='scott')\n",
    "kde_sim_a = gaussian_kde(post_values_a, bw_method='scott')\n",
    "kde_sim_b = gaussian_kde(post_values_b, bw_method='scott')\n",
    "\n",
    "x_grid_A = np.linspace(2.6,9.75, numsamples)\n",
    "pdf_values_A = kde_sim_A.evaluate(x_grid_A)\n",
    "value_opt_index_A = np.argmax(pdf_values_A)\n",
    "value_opt_A = x_grid_A[value_opt_index_A]\n",
    "\n",
    "x_grid_B = np.linspace(17.6,110.0, numsamples)\n",
    "pdf_values_B = kde_sim_B.evaluate(x_grid_B)\n",
    "value_opt_index_B = np.argmax(pdf_values_B)\n",
    "value_opt_B = x_grid_B[value_opt_index_B]\n",
    "\n",
    "x_grid_a = np.linspace(1.5,2.5, numsamples)\n",
    "pdf_values_a = kde_sim_a.evaluate(x_grid_a)\n",
    "value_opt_index_a = np.argmax(pdf_values_a)\n",
    "value_opt_a = x_grid_a[value_opt_index_a]\n",
    "\n",
    "x_grid_b = np.linspace(0.75,1.25, numsamples)\n",
    "pdf_values_b = kde_sim_b.evaluate(x_grid_b)\n",
    "value_opt_index_b = np.argmax(pdf_values_b)\n",
    "value_opt_b = x_grid_b[value_opt_index_b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e846bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_pm_true = sim_params_jr_true[0]\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "x_pdf_A =np.linspace(2.6,9.75,numsamples)\n",
    "plt.plot(x_pdf_A,pdf_values_A,linewidth=0.5)\n",
    "plt.plot(x_pdf_A[value_opt_index_A], pdf_values_A[value_opt_index_A], 'ro')\n",
    "plt.axvline(tensor_pm_true[0], color='orange')\n",
    "plt.title(\"PDF A\")\n",
    "plt.legend([\"PDF\",\"SBI A\",\"True A\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "x_pdf_B =np.linspace(17.6,110.0,numsamples)\n",
    "plt.plot(x_pdf_B,pdf_values_B,markevery=value_opt_index_B,linewidth=0.5)\n",
    "plt.plot(x_pdf_B[value_opt_index_B], pdf_values_B[value_opt_index_B], 'ro')\n",
    "plt.axvline(tensor_pm_true[1], color='orange')\n",
    "plt.title(\"PDF B\")\n",
    "plt.legend([\"PDF\",\"SBI B\",\"True B\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "x_pdf_a =np.linspace(1.5,2.5,numsamples)\n",
    "plt.plot(x_pdf_a,pdf_values_a,linewidth=0.5)\n",
    "plt.plot(x_pdf_a[value_opt_index_a], pdf_values_a[value_opt_index_a], 'ro')\n",
    "plt.axvline(tensor_pm_true[2], color='orange')\n",
    "plt.title(\"PDF a\")\n",
    "plt.legend([\"PDF\",\"SBI a\",\"True a\"])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "x_pdf_b =np.linspace(0.75,1.25,numsamples)\n",
    "plt.plot(x_pdf_b,pdf_values_b,markevery=value_opt_index_b,linewidth=0.5)\n",
    "plt.plot(x_pdf_b[value_opt_index_b], pdf_values_b[value_opt_index_b], 'ro')\n",
    "plt.axvline(tensor_pm_true[3], color='orange')\n",
    "plt.title(\"PDF b\")\n",
    "plt.legend([\"PDF\",\"SBI b\",\"True b\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c9199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_sbi_jr = torch.tensor([[value_opt_A,value_opt_B, value_opt_a, value_opt_b]])\n",
    "eeg_sbi = simulation_wrapper_prepared(params_sbi_jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5002ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(params_sbi_jr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ef35e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('final_simulation.npy', eeg_sbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d75b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = h5py.File('pre_final_sim.mat', 'r')\n",
    "signal = torch.tensor(mat['avg_final_chunk'][:])\n",
    "eeg_sbi = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839b6d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(eeg_sbi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049a3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg_sbi = np.delete(eeg_sbi, [52,55], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b130a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_offset = 250 * 4  #index of the first stimulation\n",
    "\n",
    "windows = []  #temporary list to store windows for the current simulation\n",
    "\n",
    "#generate indices for stimulations, starting from `initial_offset` and spaced by `samples_per_stimulation`\n",
    "stim_indices = torch.arange(initial_offset, eeg_sbi.shape[1] - samples_per_stimulation, samples_per_stimulation)\n",
    "    \n",
    "#for each stimulation point in the current simulation\n",
    "for idx in stim_indices:\n",
    "    start_idx = idx - pre_stimulus  #start of window\n",
    "    end_idx = idx + post_stimulus  #end of window\n",
    "\n",
    "    window = eeg_sbi[0, start_idx:end_idx, :]  \n",
    "        \n",
    "    #append the extracted window to the `windows` list\n",
    "    windows.append(window)\n",
    "\n",
    "windows = torch.stack(windows, dim=0)\n",
    "    \n",
    "#calculate the mean across all trials for the current simulation\n",
    "avg_eeg_sbi = windows.mean(dim=0)\n",
    "    \n",
    "print(avg_eeg_sbi.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283cd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "teeg = np.linspace(-50,200,1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa79401",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,10))\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(teeg[:], sim_eeg_obs[:,:],'k')\n",
    "plt.ylim(-0.02,  0.02)\n",
    "plt.title(\"EEG - OBS, channel 1-65\")\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(teeg[:], eeg_sbi[:,:].T/40000,'k')\n",
    "plt.ylim(-0.02,  0.02)\n",
    "plt.title(\"EEG - SBI, channel 1-65\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#numpy.save('Time', teeg)\n",
    "#numpy.save('SBI EEG', eeg_sbi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
